# Neural Network Implementation

## Overview
This repository contains an implementation of a simple neural network using Python and NumPy. The network includes functions for initializing weights and biases, computing weighted sums, applying activation functions, and performing forward propagation through multiple layers.

## What I Added
- **Random Initialization of Weights and Biases:** Implemented random initialization for the weights and biases of each node in the network.
- **Forward Propagation:** Added functions to compute weighted sums, apply activation functions (sigmoid), and propagate inputs through the network to generate predictions.
- **Network Initialization:** Created a flexible function to initialize networks of various sizes, including the ability to specify the number of layers and nodes per layer.

## What I Learned
- **Neural Network Basics:** Gained a deeper understanding of how neural networks operate, including the significance of weights, biases, and activation functions.
- **Implementation Details:** Learned how to implement the core components of a neural network from scratch, such as forward propagation and weight initialization.
- **NumPy Usage:** Improved proficiency with NumPy for performing mathematical operations and handling arrays efficiently.

## How to Run the Code
1. **Clone the Repository:**
   ```sh
   git clone https://github.com/yourusername/your-repository.git
   cd your-repository
2.pip install numpy

3.python [name of the file]
